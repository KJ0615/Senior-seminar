{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Publication Type                Authors Book Authors  \\\n",
      "0                  J              Ökten, AI          NaN   \n",
      "1                  J            Chalmers, S          NaN   \n",
      "2                  J             Karakis, I          NaN   \n",
      "3                  C    Abuduo, Z; Chen, LL          NaN   \n",
      "4                  J  Syamili, C; Rekha, RV          NaN   \n",
      "..               ...                    ...          ...   \n",
      "995                J               LONG, JB          NaN   \n",
      "996                J            [Anonymous]          NaN   \n",
      "997                S                    NaN          NaN   \n",
      "998                J             Nicolle, S          NaN   \n",
      "999                J              Hambly, G          NaN   \n",
      "\n",
      "                                          Book Editors Book Group Authors  \\\n",
      "0                                                  NaN                NaN   \n",
      "1                                                  NaN                NaN   \n",
      "2                                                  NaN                NaN   \n",
      "3    McAnally, E; Solovjeva, I; Zhang, Y; Green, R;...                NaN   \n",
      "4                                                  NaN                NaN   \n",
      "..                                                 ...                ...   \n",
      "995                                                NaN                NaN   \n",
      "996                                                NaN                NaN   \n",
      "997                             Zanker, KS; Kaveri, SV                NaN   \n",
      "998                                                NaN                NaN   \n",
      "999                                                NaN                NaN   \n",
      "\n",
      "                Author Full Names Book Author Full Names  Group Authors  \\\n",
      "0                Okten, Ali Ihsan                    NaN            NaN   \n",
      "1                 Chalmers, Shane                    NaN            NaN   \n",
      "2                Karakis, Ioannis                    NaN            NaN   \n",
      "3    Abuduo, ZaiNahan; Chen, Lili                    NaN            NaN   \n",
      "4       Syamili, C.; Rekha, R. V.                    NaN            NaN   \n",
      "..                            ...                    ...            ...   \n",
      "995                      LONG, JB                    NaN            NaN   \n",
      "996                   [Anonymous]                    NaN            NaN   \n",
      "997                           NaN                    NaN            NaN   \n",
      "998              Nicolle, Sylvain                    NaN            NaN   \n",
      "999                Hambly, Glenda                    NaN            NaN   \n",
      "\n",
      "                                         Article Title  \\\n",
      "0                           Mythology and Neurosurgery   \n",
      "1                                   Negative Mythology   \n",
      "2                     Neuroscience and Greek mythology   \n",
      "3    A Preliminary Study on the Types of Uygur Myth...   \n",
      "4           Developing an ontology for Greek mythology   \n",
      "..                                                 ...   \n",
      "995                        ANALYSIS OF SAIVA MYTHOLOGY   \n",
      "996                      Short Dictionary of Mythology   \n",
      "997  Mistletoe: From Mythology to Evidence-Based Me...   \n",
      "998  The Political Mythology of Paul Hadol: figures...   \n",
      "999  Cultural influences in screenwriting: Australi...   \n",
      "\n",
      "                                          Source Title  ...  \\\n",
      "0                                   WORLD NEUROSURGERY  ...   \n",
      "1                                     LAW AND CRITIQUE  ...   \n",
      "2          JOURNAL OF THE HISTORY OF THE NEUROSCIENCES  ...   \n",
      "3    PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENC...  ...   \n",
      "4                                   ELECTRONIC LIBRARY  ...   \n",
      "..                                                 ...  ...   \n",
      "995                           JOURNAL OF ASIAN STUDIES  ...   \n",
      "996                              PSYCHIATRIC QUARTERLY  ...   \n",
      "997  MISTLETOE: FROM MYTHOLOGY TO EVIDENCE-BASED ME...  ...   \n",
      "998                                 QUETES LITTERAIRES  ...   \n",
      "999                           JOURNAL OF SCREENWRITING  ...   \n",
      "\n",
      "                                  Web of Science Index  \\\n",
      "0       Science Citation Index Expanded (SCI-EXPANDED)   \n",
      "1               Emerging Sources Citation Index (ESCI)   \n",
      "2       Science Citation Index Expanded (SCI-EXPANDED)   \n",
      "3    Conference Proceedings Citation Index - Social...   \n",
      "4                 Social Science Citation Index (SSCI)   \n",
      "..                                                 ...   \n",
      "995               Social Science Citation Index (SSCI)   \n",
      "996               Social Science Citation Index (SSCI)   \n",
      "997             Book Citation Index – Science (BKCI-S)   \n",
      "998             Emerging Sources Citation Index (ESCI)   \n",
      "999           Arts & Humanities Citation Index (A&HCI)   \n",
      "\n",
      "                                        Research Areas IDS Number   Pubmed Id  \\\n",
      "0                   Neurosciences & Neurology; Surgery      DS1MS  26970479.0   \n",
      "1                                     Government & Law      LB9MK         NaN   \n",
      "2    History & Philosophy of Science; Neurosciences...      HR4DT  30332331.0   \n",
      "3    Arts & Humanities - Other Topics; Social Scien...      BM7IR         NaN   \n",
      "4                Information Science & Library Science      FW0KN         NaN   \n",
      "..                                                 ...        ...         ...   \n",
      "995                        Area Studies; Asian Studies      AB833         NaN   \n",
      "996                                         Psychiatry      V74JD         NaN   \n",
      "997  General & Internal Medicine; Research & Experi...      BG2NF         NaN   \n",
      "998                                         Literature      PO0XJ         NaN   \n",
      "999               Film, Radio & Television; Literature      LG7FB         NaN   \n",
      "\n",
      "    Open Access Designations Highly Cited Status Hot Paper Status  \\\n",
      "0                        NaN                 NaN              NaN   \n",
      "1                        NaN                 NaN              NaN   \n",
      "2                        NaN                 NaN              NaN   \n",
      "3                        NaN                 NaN              NaN   \n",
      "4                        NaN                 NaN              NaN   \n",
      "..                       ...                 ...              ...   \n",
      "995                      NaN                 NaN              NaN   \n",
      "996                      NaN                 NaN              NaN   \n",
      "997          Green Published                 NaN              NaN   \n",
      "998    Green Submitted, gold                 NaN              NaN   \n",
      "999                      NaN                 NaN              NaN   \n",
      "\n",
      "    Date of Export   UT (Unique WOS ID) Web of Science Record  \n",
      "0       2024-02-29  WOS:000380360500040                     0  \n",
      "1       2024-02-29  WOS:000524952700005                     0  \n",
      "2       2024-02-29  WOS:000463095600001                     0  \n",
      "3       2024-02-29  WOS:000467947000143                     0  \n",
      "4       2024-02-29  WOS:000424983900008                     0  \n",
      "..             ...                  ...                   ...  \n",
      "995     2024-02-29  WOS:A1975AB83300013                     0  \n",
      "996     2024-02-29  WOS:000205026100035                     0  \n",
      "997     2024-02-29  WOS:000387488800012                     0  \n",
      "998     2024-02-29  WOS:000604894800006                     0  \n",
      "999     2024-02-29  WOS:000528261000004                     0  \n",
      "\n",
      "[1000 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_excel('savedrecs.xls')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select = [\"Authors\", \"Book Authors\", \"Article Title\", \"Document Type\", \n",
    "                     \"Cited Reference Count\",\"Publisher\",\"Publisher City\",\n",
    "                     \"Publication Year\",\"Start Page\",\"End Page\",\"Abstract\"]\n",
    "filtered_df = df[columns_to_select]\n",
    "filtered_df = filtered_df.dropna(subset=['Abstract'])\n",
    "X = filtered_df['Abstract']\n",
    "y = filtered_df['Document Type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                   Article       0.78      1.00      0.87        76\n",
      "     Article; Book Chapter       0.00      0.00      0.00         3\n",
      "     Article; Early Access       0.00      0.00      0.00        10\n",
      "Article; Proceedings Paper       0.00      0.00      0.00         1\n",
      "         Proceedings Paper       0.00      0.00      0.00         6\n",
      "                    Review       0.00      0.00      0.00         2\n",
      "\n",
      "                  accuracy                           0.78        98\n",
      "                 macro avg       0.13      0.17      0.15        98\n",
      "              weighted avg       0.60      0.78      0.68        98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liam/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/liam/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/liam/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "y_pred = clf.predict(X_test_vectors)\n",
    "print(classification_report(y_test, y_pred))  # target_names can be specified if you have them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: This is the ratio of true positive predictions to the total predicted positives. High precision relates to a low false positive rate. For the class \"Article\", you have a precision of 0.78, meaning that when the model predicts an \"Article\", it is correct about 78% of the time.\n",
    "\n",
    "Recall: This is the ratio of true positives to the actual total positives. High recall means that the classifier is returning most of the relevant results. For \"Article\", the recall is 1.00, which indicates that the model identified all \"Article\" instances correctly.\n",
    "\n",
    "F1-Score: This is the harmonic mean of precision and recall. An F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. For \"Article\", the F1 score is quite high at 0.87, which is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk>=3.8 (from textblob)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/liam/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/liam/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/liam/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.8->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/liam/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.8->textblob) (4.64.1)\n",
      "Installing collected packages: nltk, textblob\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "Successfully installed nltk-3.8.1 textblob-0.18.0.post0\n",
      "[nltk_data] Downloading package brown to /Users/liam/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/liam/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /Users/liam/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/liam/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package conll2000 to /Users/liam/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/liam/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# Install TextBlob and its necessary corpora\n",
    "!pip install textblob\n",
    "!python -m textblob.download_corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word: myth\n",
      "Synset 1: myth.n.01\n",
      "Definition: a traditional story accepted as history; serves to explain the world view of a people\n",
      "Lemma: myth\n",
      "\n",
      "Word: mythology\n",
      "Synset 1: mythology.n.01\n",
      "Definition: myths collectively; the body of stories associated with a culture or institution or person\n",
      "Lemma: mythology\n",
      "Synset 2: mythology.n.02\n",
      "Definition: the study of myths\n",
      "Lemma: mythology\n",
      "\n",
      "Word: Myth\n",
      "Synset 1: myth.n.01\n",
      "Definition: a traditional story accepted as history; serves to explain the world view of a people\n",
      "Lemma: Myth\n",
      "\n",
      "Word: Mythology\n",
      "Synset 1: mythology.n.01\n",
      "Definition: myths collectively; the body of stories associated with a culture or institution or person\n",
      "Lemma: Mythology\n",
      "Synset 2: mythology.n.02\n",
      "Definition: the study of myths\n",
      "Lemma: Mythology\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Define the words to analyze\n",
    "words = [\"myth\", \"mythology\", \"Myth\", \"Mythology\"]\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "for word in words:\n",
    "    # Get the synsets (sets of synonyms) for the word\n",
    "    synsets = wordnet.synsets(word)\n",
    "\n",
    "    # Print the word and its synsets\n",
    "    print(f\"\\nWord: {word}\")\n",
    "    for i, synset in enumerate(synsets):\n",
    "        # Get the definition and example sentences for the synset\n",
    "        definition = synset.definition()\n",
    "        examples = synset.examples()\n",
    "\n",
    "        print(f\"Synset {i+1}: {synset.name()}\")\n",
    "        print(f\"Definition: {definition}\")\n",
    "        if examples:\n",
    "            print(\"Examples:\")\n",
    "            for example in examples:\n",
    "                print(f\"- {example}\")\n",
    "\n",
    "        # Get the lemma (root form) of the word\n",
    "        lemma = lemmatizer.lemmatize(word, pos=synset.pos())\n",
    "        print(f\"Lemma: {lemma}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
